{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCanela-1954/DataSci_Course/blob/main/%5BDATA-05E%5D%20Example%20-%20Bay%20Wheels%20operations%20data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [DATA-05E] Example - Bay Wheels operations data"
      ],
      "metadata": {
        "id": "uLRmXc_rtEQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "9qb8kiFrSKvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bike sharing systems** are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout an urban area. Using these systems, people are able to rent a bike from one location and return it to a different place on an as-needed basis. According to PBSC Urban Solutions, there were, as of August 2021, nearly 10 million shared bikes and 3,000 bike sharing systems across the world.\n",
        "\n",
        "There is a great interest in these systems due to their important role in traffic, environmental and health issues. Apart from interesting real world applications of bike sharing systems, the characteristics of the data generated by these systems makes them attractive for researchers. Opposed to other transport services such as bus or subway, the duration of travel, departure location, arrival location and time elapsed is explicitly recorded. This feature turns a bike sharing system into a virtual sensor network, which can be used for studying mobility within the area. Hence, it is expected that most of important events in the area could be detected via monitoring these data.\n",
        "\n",
        "This example uses two years of data from the **Bay Wheels Bike Share Program**, which brings point-to-point bike sharing to Bay Area cities, serving Berkeley, Emeryville, Oakland, San Jose and San Francisco. Bay Wheels is a partnership between MTC, the five local governments, and Motivate (a subsidiary of Lyft).  \n",
        "\n",
        "The Bay Wheels Program has undergone a bit of change. It started as the Bay Area Bike Share in August 2013. On June 28, 2017, the system was officially re-launched as Ford GoBike in a partnership with Ford Motor Company. After Motivate's acquisition by Lyft, the system was renamed to Bay Wheels on June 11, 2019. In 2018, Ford GoBike added **electric bicycles** and **dockless bike share**. Nowadays, electric bicycles account for two thirds of the rides. Classic bikes are docked, so they are picked at one station and left at another station (or at the same one). E-bikes can use the **docking stations** or can be locked to a **city bike rack**."
      ],
      "metadata": {
        "id": "2hTqIBMwSO8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The data set"
      ],
      "metadata": {
        "id": "TUKIlT02SgMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data for the example come in two tables. The table `bay_stations` (a CSV file) contains data on 642 docking stations. These stations are not the same along the three-year period, since the organization is dynamic. The columns are:\n",
        "\n",
        "* `station_id`, a unique identifier of the station. The first two characters indicate the location, with values 'BK' (Berkeley), 'SF' (San Francisco), 'SJ' (San Jose) and 'OK' (Oakland).\n",
        "\n",
        "* `station_name`, the name of the station, referred to its location.\n",
        "\n",
        "* `station_latitude`, the latitude of the station, with three decimals.\n",
        "\n",
        "* `station_longitude`, the longitude of the station, with three decimals.\n",
        "\n",
        "The table `bay_rides` (five zipped CSV files) contains information on all rides starting in the years 2021, 2022 and 2023, a total of 7,162,392 rides. The columns are:\n",
        "\n",
        "* `user_type`, either 'casual' or 'member'.\n",
        "\n",
        "* `bike_type`, either 'classic' or 'electric'.\n",
        "\n",
        "* `start_time`, when the bike was picked, as yyyy-mm-dd hh:mm:ss.\n",
        "\n",
        "* `start_station_id`, the identifier of the docking station where the ride started, missing when no station was involved.\n",
        "\n",
        "* `end_time`, when the bike was returned, as yyyy-mm-dd hh:mm:ss.\n",
        "\n",
        "* `end_station_id`, the identifier of the docking station where the ride ended, missing when no station was involved."
      ],
      "metadata": {
        "id": "3znam26HSkBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions"
      ],
      "metadata": {
        "id": "ALqcQ94WS4ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Add a new column, `hour`, to the table `rides`, containing the hour of the start time, in `datetime64` format. Example: the hour for `2021-01-01 01:20:23` will be `2021-01-01 01:00:00`.\n",
        "\n",
        "Q2. **Group by** `hour` and **aggregate** the data so that you get a a new table with two columns, `casual` and `member`, containing, for every hour, the total number of rides of the types of users.\n",
        "\n",
        "Q3. After aggregating the data in the preceding question, can see you see a **time trend** in the number of rides? To visualize the trend, would it be better to aggregate more, *e.g*. to use daily data? Do you see a similar trend for the two user types?\n",
        "\n",
        "Q4. Can you describe in an easy way the pattern for **intraday variation** (across hours) of the number of rides? Is this pattern different for the two user types?\n",
        "\n",
        "Q5. Same questions for **intraweek variation** (across weekdays).\n",
        "\n",
        "Q6. What about **monthly seasonality**?"
      ],
      "metadata": {
        "id": "iVgSc5L2S7cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the data"
      ],
      "metadata": {
        "id": "v_we1DcYtkkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import Pandas as usual."
      ],
      "metadata": {
        "id": "ggWobf07TG6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3UwVIcZrtpoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table `rides` has been split in five data sets stored in zipped CSV files in GitHub, with a common path. So, we create a variable containing that path."
      ],
      "metadata": {
        "id": "NHYSlJ2mTLkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/MCanela-1954/Data/main/'"
      ],
      "metadata": {
        "id": "lksk2muGtrwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we import the data from every files to a data frame."
      ],
      "metadata": {
        "id": "5sXn3-PiTP_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides1 = pd.read_csv(path + 'bay_rides-1.csv.zip')\n",
        "rides2 = pd.read_csv(path + 'bay_rides-2.csv.zip')\n",
        "rides3 = pd.read_csv(path + 'bay_rides-3.csv.zip')\n",
        "rides4 = pd.read_csv(path + 'bay_rides-4.csv.zip')\n",
        "rides5 = pd.read_csv(path + 'bay_rides-5.csv.zip')"
      ],
      "metadata": {
        "id": "0yCpeZmVtwa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the Pandas function `concat()`, we can get the **union** of these five data sets as a single data frame."
      ],
      "metadata": {
        "id": "6coUB-lZTr9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides = pd.concat([rides1, rides2, rides3, rides4, rides5])"
      ],
      "metadata": {
        "id": "4sLQxPRlt1w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the data"
      ],
      "metadata": {
        "id": "sE8I00m0t4EB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check the content of the data frame `rides` as in other examples, with the methods `.info()` and `.head()`. Everything is as expected. Note that the station ID is missing for some of the electric bikes, as explained in the introduction."
      ],
      "metadata": {
        "id": "G_jv4Fu-YBhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides.info()"
      ],
      "metadata": {
        "id": "7cvN2yELt-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rides.head()"
      ],
      "metadata": {
        "id": "F3GET3S-t_4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Add a column with the hour"
      ],
      "metadata": {
        "id": "2XtHYgR7uD62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The start and end times have type `str`, so we can create the new column by means of string methods. There many ways to do it. A simple one is to drop the last six characters, which are the minutes and seconds, appending instead the string `':00:00'`."
      ],
      "metadata": {
        "id": "OqZSvPTSYXgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides['hour'] = rides['start_time'].str[:-6] + ':00:00'\n",
        "rides.head()"
      ],
      "metadata": {
        "id": "S5-uyp_rue2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert this new column to a datetime type, in order to be able to extract the weekdays. **Type conversions** in Pandas are easily managed with the method `.astype()`."
      ],
      "metadata": {
        "id": "l9EjbGaFZACt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides['hour'] = rides['hour'].astype('datetime64[ns]')\n",
        "rides.info()"
      ],
      "metadata": {
        "id": "83XYxXR8Y9aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. Aggregate to hourly data"
      ],
      "metadata": {
        "id": "K6BU9BhAxUQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build the data set for this question we need two additional columns, `casual` and `member`. We create them as dummies, so that we can aggregate them in order to get the number of rides for each group."
      ],
      "metadata": {
        "id": "kij_Pl7EZHOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides['casual'] = (rides['user_type'] == 'casual')\n",
        "rides['member'] = (rides['user_type'] == 'member')"
      ],
      "metadata": {
        "id": "4j8EAIpJxw7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we group by hour and aggregate with the function `sum()`. To get a cleaner picture, we include only the columns that are relevant for the rest of this example. Note the double bracketing, which is needed, since the columns included have to be specified as a list."
      ],
      "metadata": {
        "id": "8UeKESI5chjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = rides[['hour', 'casual', 'member']].groupby(by='hour').sum()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4B4fYTEuzP8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `hour` is no longer a column, but the index. This is the default of the method `.groupby()`. Because of the type conversion performed above, to data type `datetime64`, this index is a `DatetimeIndex`."
      ],
      "metadata": {
        "id": "qxWQLepecv31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.index"
      ],
      "metadata": {
        "id": "FaGfZP6izc_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3. Time trend"
      ],
      "metadata": {
        "id": "PHE7rkyEzoEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get rid of the index name, so that it will not appear in the plots below, which might be confusing."
      ],
      "metadata": {
        "id": "ZoAXVOgWc-CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.index.name = None"
      ],
      "metadata": {
        "id": "-u7Trh_NKuBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For clarity, we create a new column with the total number of rides."
      ],
      "metadata": {
        "id": "MBT8-HjpdH8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total'] = df['member'] + df['casual']"
      ],
      "metadata": {
        "id": "v3LRG2ZBK4px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time trends are typically spotted by means of **line charts**. See below a sample using the hourly total number of rides."
      ],
      "metadata": {
        "id": "vQvT-5eKewwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total'].plot(figsize=(8,5), title='Figure 1. Hourly total demand', color='black', linewidth=1);"
      ],
      "metadata": {
        "id": "8xNy84rGK67n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see here a combination of a trend with time-based patterns, but it is difficult to conclude much with so many observations and the current granularity of the data. Since intraday patterns can be responsible for a significant part of the variation that we see in the chart, we aggregate to a daily data set. We use the mean so the vertical scale in the successive charts remains the same. Note that, here, we don't use `.groupby()`, but `.resample()`, and we don't need to create a new data set for plotting."
      ],
      "metadata": {
        "id": "PjJuOm31e5Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total'].resample('D').mean().plot(figsize=(8,5), title='Figure 2. Daily total demand',\n",
        "\tcolor='black', linewidth=1);"
      ],
      "metadata": {
        "id": "YS61GSxwK-LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the picture is more clear, though part of the variation is probably due to weekends and holidays. Going a bit further, we can aggregate to a weekly data set, again with `.resample()`."
      ],
      "metadata": {
        "id": "UcdJjg35fCeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total'].resample('W').mean().plot(figsize=(8,5), title='Figure 3. Weekly total demand',\n",
        "\tcolor='black', linewidth=1);"
      ],
      "metadata": {
        "id": "86kSYIb7LIL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can aggregate the data even further, to a monthly data set. The new chart shows a combination of a trend plus monthly seasonality."
      ],
      "metadata": {
        "id": "gq0ER-pZfHrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total'].resample('ME').mean().plot(figsize=(8,5), title='Figure 4. Monthly total demand',\n",
        "\tcolor='black', linewidth=1);"
      ],
      "metadata": {
        "id": "myls4D_YLW8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see whether the trend is the same for the two user types, we can draw separate charts, which show that the trend only happens in the member group. This may be due to workforce discontinuing remote work and going back to office after the Stay Home order."
      ],
      "metadata": {
        "id": "OSGVj2ABfP68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['casual'].resample('ME').mean().plot(figsize=(8,5), title=\"Figure 5. Casuals' monthly total demand\",\n",
        "\tcolor='black', linewidth=1);"
      ],
      "metadata": {
        "id": "kt1YWR75LjPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['member'].resample('ME').mean().plot(figsize=(8,5), title=\"Figure 6. Members' monthly total demand\",\n",
        "\tcolor='black', linewidth=1);"
      ],
      "metadata": {
        "id": "Gml8OJbFLtVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4. Intraday variation"
      ],
      "metadata": {
        "id": "ZMnJVfyNL3e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To examine the intraday variation, we need to extract an average value for every hour. First, we create a column containing (only) the hour, as an integer, with the method `.hour`."
      ],
      "metadata": {
        "id": "-Ep_tLE8hxuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['hour'] = df.index.hour\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MBOFTABTM20l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we group by hour and aggregate to 24 average values. For the casual users, the aggregate data look like:"
      ],
      "metadata": {
        "id": "_nzNkDj6h8OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['casual', 'hour']].groupby('hour').mean().round(1))"
      ],
      "metadata": {
        "id": "c3WvXMVpNHAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may prefere to see this in a **bar chart**. Comparing the charts of the two user types, we see the influence of work schedule in the intraday variation pattern of the members.  "
      ],
      "metadata": {
        "id": "neCqmjHOia0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['casual', 'hour']].groupby('hour').mean().plot.bar(figsize=(7,5),\n",
        "\ttitle=\"Figure 7. Intraday variation of casuals' average demand\", color='gray', legend=False);"
      ],
      "metadata": {
        "id": "jjkRspdsNUIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['member', 'hour']].groupby('hour').mean().plot.bar(figsize=(7,5),\n",
        "\ttitle=\"Figure 8. Intraday variation of members' average demand\", color='gray', legend=False);"
      ],
      "metadata": {
        "id": "7z7SdetXNaQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or you may prefer to pack both charts as a **stacked bar chart**, which is easy in Pandas, as we see next."
      ],
      "metadata": {
        "id": "bqYFKbvDikiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['casual', 'member', 'hour']].groupby('hour').mean().plot.bar(figsize=(7,5),\n",
        "\ttitle='Figure 9. Intraday variation of average demand', color=['0.4', '0.7'], stacked=True);"
      ],
      "metadata": {
        "id": "lF06Q_xTNkAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. Intraweek variation"
      ],
      "metadata": {
        "id": "hfscrKqaN2nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A similar approach can be followed for the intraweek variation. First, we create a new column by extracting the weekday from the index, now with `.weekday` (Monday = 0, Sunday = 6)."
      ],
      "metadata": {
        "id": "pQNaL9QZjJ87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['weekday'] = df.index.weekday"
      ],
      "metadata": {
        "id": "EuFu8VEtPKKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stacked bar chart is obtained as for question Q4. As for the intraday variation, the different patterns visualized suggest that members and casuals use the bike  travelling with different purposes (work/leisure)."
      ],
      "metadata": {
        "id": "C3FVH2C4jQzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['casual', 'member', 'weekday']].groupby('weekday').mean().plot.bar(figsize=(7,5),\n",
        "\ttitle= 'Figure 10. Intraweek variation of total demand', color=['0.4', '0.7'], stacked=True);"
      ],
      "metadata": {
        "id": "ouz_7zcYPZkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. Monthly seasonality"
      ],
      "metadata": {
        "id": "PGf_0opUPdEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the monthly seasonality by means of twelve monthly averages. Again, we create a new column, now with months (January = 1, December = 12)."
      ],
      "metadata": {
        "id": "mgmIImDjjWNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['month'] = df.index.month\n",
        "df[['casual', 'member', 'month']].groupby('month').mean().round(1)"
      ],
      "metadata": {
        "id": "y0r8uBSrRHry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can plot just plot the total demand here, since the seasonal patterns are about the same for casuals and members."
      ],
      "metadata": {
        "id": "8zRroScajvdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['total', 'month']].groupby('month').mean().plot(figsize=(8,5),\n",
        "    title='Figure 11. Monthly seasonality', color='black', linewidth=1, legend=False);"
      ],
      "metadata": {
        "id": "H-nvQvMERL3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework"
      ],
      "metadata": {
        "id": "5k7xLoEHj5ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Perform an analysis of the demand in which the patterns of variation for the demand of electric and classic bikes are compared. Are classic bikes lagging behind electric bikes?\n",
        "\n",
        "2. Which are the top-10 starting stations? Are they the same as the top-10 ending stations?\n",
        "\n",
        "3. How frequent are circular rides, starting and ending at the same station?\n",
        "\n",
        "4. Are there stations with very low activity, so you can consider dropping them?\n",
        "\n",
        "5. Seasonal patterns can be different across the stations of the Bay Wheels network. How can you detect the stations where the between-month variation is highest?\n"
      ],
      "metadata": {
        "id": "LKW056ibjxWq"
      }
    }
  ]
}