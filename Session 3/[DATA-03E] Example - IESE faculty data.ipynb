{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN8p6y21FOx8vGM98kx29Qn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCanela-1954/DataSci_Course/blob/main/%5BDATA-03E%5D%20Example%20-%20IESE%20faculty%20data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [DATA-03E] Example - IESE faculty data"
      ],
      "metadata": {
        "id": "20rhIQwEQtm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "DTsWjYRn6DRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we are going to scrape data on the professors from the website of IESE Business School. The tools used are taken from the Python packages **Requests** and **Beautiful Soup**. Both packages are available in Colab notebooks. Requests is included in the Anaconda distribution, but Beautiful Soup is not. You can install it in your computer by running `pip install bs4` in the shell or in a Jupyter app.\n",
        "\n",
        "The basic information on the IESE faculty is posted on seven webpages. Except the last one, each of these pages contains information on 20 professors. The URL for the first page is `https://www.iese.edu/search/professors/1/` (if you omit the number at the end you will get also the first page). The rest of the pages are obtained by increasing the counter. We will see first how to work on the first page, and then we will loop over the rest of the pages.\n"
      ],
      "metadata": {
        "id": "8kD8EO_76GHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The target data"
      ],
      "metadata": {
        "id": "4meoD6ON6POp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We aim at capturing the following fields:\n",
        "\n",
        "* `name`, the complete name of the professor. Example: Javier\n",
        "Aguirreamalloa Arizaga.\n",
        "\n",
        "* `job`, the job title of the professor. Example: Associate Professor of the Practice of Management of Financial Management.\n",
        "\n",
        "* `link`, the URL for the professor's personal page. Example: `https://www.iese.edu/faculty-research/faculty/javier-aguirreamalloa-arizaga/`.\n",
        "\n",
        "* `picture`, the URL for the professor's picture. Example: `https://www.iese.edu/wp-content/uploads/2018/11/Aguirreamalloa_Javier-1.jpg`."
      ],
      "metadata": {
        "id": "cAO5otxB6R2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capturing the source code"
      ],
      "metadata": {
        "id": "bGpXy2opQ9a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import Requests as:"
      ],
      "metadata": {
        "id": "1_Yim3cd6cgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "4QItUXOcRGb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get source code of a web page, we apply the Requests function `get()` to the URL of that page. When the request is accepted, as in this case, this function returns an object of a special type (type `requests.models.Response`). The attribute `.text` of this object is a string which, for an ordinary webpage, is the source HTML code of that page."
      ],
      "metadata": {
        "id": "GG87ehaM6rEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_str = requests.get('https://www.iese.edu/search/professors/1/').text"
      ],
      "metadata": {
        "id": "CMpeLB5SRKME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, `html_str` is a string containing the source code of the IESE faculty first page."
      ],
      "metadata": {
        "id": "FrAYRklE6u2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing the source code"
      ],
      "metadata": {
        "id": "V2FwjoorRPiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To **parse** the source code, learning the tree structure it conveys, we use the function `BeautifulSoup()`, from the package `bs4` (Beautiful Soup, version 4). We import this function with:"
      ],
      "metadata": {
        "id": "oOmyH7KmQWfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "EQzWXuXtSXKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`BeautifulSoup()` converts the string `html_str` to a \"soup\" object:"
      ],
      "metadata": {
        "id": "bOkopYWjQt9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html_str, 'html.parser')"
      ],
      "metadata": {
        "id": "E9z0EvOKSaTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The first professor"
      ],
      "metadata": {
        "id": "fhIHHGN0Sb1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In web scraping jobs, we take advantage of the fact that web pages posting information units in a systematic way have a repetitive structure, made of a set of HTML elements with the same names and attributes values. This is, precisely, what allows IESE to update the pages in a programmatic way, in order to cope with the changes in the faculty composition.\n",
        "\n",
        "To use the methods `.find()` and `.find_all()`, we need to know the name of the HTML element and, sometimes, some of the attributes. How can we find this? There are many ways, and every practitioner has his/her own cookbook. We use here a simple approach, based on the browser tools. More specifically, the *Inspect* tool of the browser.\n",
        "\n",
        "In the browser, we right-click on the area where the information sought is stored. A contextual menu pops up, in which we select *Inspect*. This opens the panel *Developer Tools*. The *Elements* window in this panel shows a view of the source code corresponding to the area on which we have clicked.\n",
        "\n",
        "Let us do this where the information on the first professor is displayed. This is a rectangular area, with the picture on top, and the name and job below. In the *Elements* window, this is the first of a series of elements with the same start tag:\n",
        "\n",
        "```\n",
        "<div class=\"col-12 col-md-4 col-lg-3 employee-card-box\">\n",
        " ```\n",
        "\n",
        "The method `.find()` gives the first of these elements, which corresponds to the first professor."
      ],
      "metadata": {
        "id": "b2nD5UbYDvuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block1 = soup.find('div', 'col-12 col-md-4 col-lg-3 employee-card-box')\n",
        "block1"
      ],
      "metadata": {
        "id": "2duEjJX_Skuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The four pieces of information we wish to capture come in the following descendants:\n",
        "\n",
        "* An `a` element of class `employee-card-link` contains the link to the professor's page.\n",
        "\n",
        "* The link to the professor's picture appears twice: in an `img` element of class `image-fluid lazyload`, and in `noscript` element. We will use the `img` element, leaving aside the `noscript` element, which is included just in case Javascript is not available for your browser.\n",
        "\n",
        "* A `p` element of class `employee-card__description__name` contains the professor's name. A `p` tag is about the same as a `div`, the only difference  being that a `p` element is meant to contain paragraphs of text and a `div` element can contain anything.\n",
        "\n",
        "* A `p` element of class `employee-card__description__job` contains the professor's job.\n",
        "\n",
        "So, we can use `.find()` to capture these four values. Let us follow the order in which have specified them above."
      ],
      "metadata": {
        "id": "pVtZMoSPTa7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = block1.find('p', 'employee-card__description__name')\n",
        "name"
      ],
      "metadata": {
        "id": "yYRGN7W_Sty9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can extract the name with `.string`:"
      ],
      "metadata": {
        "id": "Z5f3-ZBKE3m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = name.string\n",
        "name"
      ],
      "metadata": {
        "id": "cWudCEcWSwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We repeat this for the job."
      ],
      "metadata": {
        "id": "YWmqEWJ9UYQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = block1.find('p', 'employee-card__description__job').string\n",
        "job"
      ],
      "metadata": {
        "id": "YVUgM3ZES1D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the link for the personal page comes as an `href` attribute value. So, we use a diferent procedure."
      ],
      "metadata": {
        "id": "XTaXOPRcWTDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link = block1.find('a', 'employee-card-link')['href']\n",
        "link"
      ],
      "metadata": {
        "id": "h9NJ-BxsUjd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use for the image the same procedure as for the link. Note that `img` element does not have an end tag. This is an exception, which is explained by the fact that these elements never contain text."
      ],
      "metadata": {
        "id": "aj7bJvwBGxzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "picture = block1.find('img', 'image-fluid lazyload')['data-src']\n",
        "picture"
      ],
      "metadata": {
        "id": "MtdcWfldWYvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can pack this information in various ways. Let us follow a JSON style, using a Python dictionary. We write a function for this task."
      ],
      "metadata": {
        "id": "YepD1P_ZHiy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_block_info(block):\n",
        "    name = block.find('p', 'employee-card__description__name').string\n",
        "    job = block.find('p', 'employee-card__description__job').string\n",
        "    link = block.find('a', 'employee-card-link')['href']\n",
        "    picture = block.find('img', 'image-fluid lazyload')['data-src']\n",
        "    dict = {'name': name, 'job': job, 'link': link, 'picture': picture}\n",
        "    return dict"
      ],
      "metadata": {
        "id": "4-5nTt6uH-A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us see how this works on the first block"
      ],
      "metadata": {
        "id": "VBK9j0pBUOIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_block_info(block1)"
      ],
      "metadata": {
        "id": "F8V6VDwgIdDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is over. Next, we loop over the 20 blocks."
      ],
      "metadata": {
        "id": "l3iW_ERlI7OJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The first page"
      ],
      "metadata": {
        "id": "YxyDDLACqfM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create first a list of 20 blocks, to loop over. This is easily done, by replacing `.find()` by `.find_all()`."
      ],
      "metadata": {
        "id": "UEV0eaCvXBAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blocks = soup.find_all('div', 'col-12 col-md-4 col-lg-3 employee-card-box')"
      ],
      "metadata": {
        "id": "-PWSJajMIpHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This should be a list of 20 HTML elements."
      ],
      "metadata": {
        "id": "K75mxHuEKZ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(blocks)"
      ],
      "metadata": {
        "id": "1u_Aqw1hqeqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To loop over these 20 blocks, we use s **list comprehension**."
      ],
      "metadata": {
        "id": "-XYSXOINYmsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [get_block_info(block) for block in blocks]"
      ],
      "metadata": {
        "id": "-bquzT0EqeRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check."
      ],
      "metadata": {
        "id": "9_zZcuJsK_vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "Ap3OhqQxLEMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "metadata": {
        "id": "bqpzTzOqLXO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are done here, Javier is on top and Veronica at the bottom. We go now for the other six pages."
      ],
      "metadata": {
        "id": "yM6wEnjoLdA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The complete faculty"
      ],
      "metadata": {
        "id": "7zwd_0aNUlTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple loop over the seven pages will do the job. We start with an empty list and append the data from every page to the current list."
      ],
      "metadata": {
        "id": "dB7oh0R4VAEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i in range(1, 8):\n",
        "    html_str = requests.get(f'https://www.iese.edu/search/professors/{i}/').text\n",
        "    soup = BeautifulSoup(html_str, 'html.parser')\n",
        "    blocks = soup.find_all('div', 'col-12 col-md-4 col-lg-3 employee-card-box')\n",
        "    newdata = [get_block_info(block) for block in blocks]\n",
        "    data = data + newdata"
      ],
      "metadata": {
        "id": "x3VhfSaClQpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "qBhp3F17X512"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last item should contain the data on the last professor, Christoph. Indeed:"
      ],
      "metadata": {
        "id": "C_K2L18FYSLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "metadata": {
        "id": "SJX1N2BmYizl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can manage these data in many ways. For instance, you may wish to have them as a Pandas data frame."
      ],
      "metadata": {
        "id": "iYxJlUUXYDNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "tw2L3DSdssSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "sGuHAL5R0OGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.tail())"
      ],
      "metadata": {
        "id": "9LAewKta0Qjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can export this to a CSV file, and save it in MyDrive, as follows."
      ],
      "metadata": {
        "id": "VJhmznLu0TrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IoP2mczH0cbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/faculty.csv', index=False)"
      ],
      "metadata": {
        "id": "Kd5XsuNWZnZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can export the data to a JSON file, which is trivial from Pandas."
      ],
      "metadata": {
        "id": "2r3yuZeyOCFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_json('/content/drive/MyDrive/faculty.json', index=False)"
      ],
      "metadata": {
        "id": "xa5VzeEMN-Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework"
      ],
      "metadata": {
        "id": "eRfiU0RHZ8wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Export the faculty data to a table of the SQLite `iese.db` database created in the example DATA-02E.\n",
        "\n",
        "2. Query this table to extract a list of the associate professors. You can help yourself with Gemini to refresh your SQL."
      ],
      "metadata": {
        "id": "byldWKKHaIqJ"
      }
    }
  ]
}
