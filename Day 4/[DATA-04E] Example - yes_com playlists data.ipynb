{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjTjsOW4lCzX9VzlGEuq2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCanela-1954/DataSci_Course/blob/main/%5BDATA-04E%5D%20Example%20-%20yes_com%20playlists%20data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [DATA-04E] Example - yes.com playlists data"
      ],
      "metadata": {
        "id": "p6UhsW3HL4XE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "9qb8kiFrSKvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example uses playlists data to illustrate the use of **vector embeddings** in **recommender systems**. The data were collected by Shuo Chen from the Department of Computer Science, Cornell University. The playlists were crawled from Yes.com, a website providing radio lists from hundreds of radio stations in the United States. At that time, through the web based API http://api.yes.com, one could retrieve the playlist record of a specified station for the last 7 days.\n",
        "\n",
        "Chen collected as many playlists as possible by searching for all the possible genres at all the possible stations. The data collection lasted from December 2010 to May 2011. This led to a data set of 11,137 playlists, containing 75,262 different songs and 2,840,553 transitions."
      ],
      "metadata": {
        "id": "RPngQK88MHrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The data set"
      ],
      "metadata": {
        "id": "PdKv53bkLpuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The playlists come in the text file `playlists.txt`, each playlist in one line. The playlist is a sequence of numbers, which are the song ID's (from 0 to the total number of songs minus one), separated by a white space. In this file, each line is ended by a space.\n",
        "\n",
        "A second file, `songs.txt`, contains data on the songs. Each line corresponds to one song, and has the format `Integer_ID \\t Title \\t Artist \\n` (`\\t` is the tab character in Python). When data were missing, a dash was placed instead.\n",
        "\n",
        "Sources:\n",
        "\n",
        "1. S Chen, JL Moore, D Turnbull & T Joachims (2012), *Playlist Prediction via Metric Embedding*, ACM Conference on Knowledge Discovery and Data Mining (KDD).\n",
        "\n",
        "2. JL Moore, S Chen, T Joachims & D Turnbull (2012), *Learning to Embed Songs and Tags for Playlists Prediction*, International Society for Music Information Retrieval (ISMIR)."
      ],
      "metadata": {
        "id": "_o00B_t2LxyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the playlists data"
      ],
      "metadata": {
        "id": "Dv3-mIKxMi5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the playlists data set is not tabular, we cannot import it to a Pandas data frame. We use the package Requests to import it to a string. First, we import the package."
      ],
      "metadata": {
        "id": "nYq4qtxiCGab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "-DD36FJcP1Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file `playlists.txt` has the same path as other data sources used in this course."
      ],
      "metadata": {
        "id": "wUNcjh5XNlOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/MCanela-1954/Data/main/'"
      ],
      "metadata": {
        "id": "BHf7QhKnN_zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the Requests function `get()` to the URL resulting from appending the file name to this path. The request is accepted, and the attribute `.text` of the object returned is a string equal to the content of the text file."
      ],
      "metadata": {
        "id": "zPB_DoqjQQ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "playlists = requests.get(path + 'playlists.txt').text"
      ],
      "metadata": {
        "id": "x1hHWW_WP8nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We **split** this string as a list of strings, one for each line. This can be done with the method `.split()`, using the new line character `\\n` as the **separator**."
      ],
      "metadata": {
        "id": "OsWKb6DwDohw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "playlists = playlists.split('\\n')"
      ],
      "metadata": {
        "id": "urSuTaTWL_ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split now every string in this list as a list of strings, using now the default separator, which is the white space."
      ],
      "metadata": {
        "id": "dssg63IEEWdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "playlists = [p.split() for p in playlists]"
      ],
      "metadata": {
        "id": "OK5eAsePNlFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, `playlists` is a list of lists, every one containing the ID's of the songs for the corresponding playlist. Let us check the number of playlists."
      ],
      "metadata": {
        "id": "zuubFLSgF0V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(playlists)"
      ],
      "metadata": {
        "id": "Tuty_Yb3SunI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also take a look to a couple of these playlists."
      ],
      "metadata": {
        "id": "l1LdWgijGUIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(playlists[0])"
      ],
      "metadata": {
        "id": "9moP51oZSxug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(playlists[-1])"
      ],
      "metadata": {
        "id": "Um-RqlwuS8C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the songs data"
      ],
      "metadata": {
        "id": "qD1se_fhHMNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the songs data set comes as a table, we can use the Pandas function `read.csv()` to import the data to a data frame. Note that we specify a separator here, since this is not a true \"comma\" separated file. We also have to specify the column names, because the source file has no **header**."
      ],
      "metadata": {
        "id": "DpC2R9yBWuFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "songs = pd.read_csv(path + 'songs.txt', sep='\\t', header=None)\n",
        "songs.columns = ['id', 'title', 'artist']"
      ],
      "metadata": {
        "id": "0cl8uN-2VS7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the contents of this data frame."
      ],
      "metadata": {
        "id": "mk2Kp1kUHgow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "songs.info()"
      ],
      "metadata": {
        "id": "3vPWSPk2HfRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs.head()"
      ],
      "metadata": {
        "id": "F0oPMZTfbHrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the playlists"
      ],
      "metadata": {
        "id": "Ux1mMQ5XX-wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to measure the similarity between songs, to use an **embedding representation**. We use **Word2Vec** to create the embedding vectors from the playlists. Word2vec comes in the Python package `gensim`.\n",
        "\n",
        "This package is not available for Colab notebooks, so we have to install it with `pip`. The role of the **exclamation mark** is to tell Colaboratory that this is a command to be executed in the shell (Colab notebooks run in a Linux virtual machine).\n",
        "\n",
        "*Note*. In your computer, you install a package only once, but in Colaboratory it is uninstalled when the notebook is disconnected. So, in practice, the package is reinstalled every time that you run the notebook."
      ],
      "metadata": {
        "id": "Vegr3Yh-YM39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "qCMam2VgJ_HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can get Word2Vec as a function from the subpackage `gensim.models`."
      ],
      "metadata": {
        "id": "bX1TrpZJKNUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "i3DDuV9fX-jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this function, we can train a Word2Vec model on the playlists data. We use here **embedding dimension** 32, but you can try other choices. Don't make the vectors too long."
      ],
      "metadata": {
        "id": "rJCD9rkwgCuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(playlists, vector_size=32)"
      ],
      "metadata": {
        "id": "C5-Beh7yYvV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `Word2vec()` returns an object containing various things. The vectors are packed in the object `model.wv`."
      ],
      "metadata": {
        "id": "OiBzjM1ULAYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(model.wv)"
      ],
      "metadata": {
        "id": "Mb1M3W93ZgtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Though this is an Gensim object of a specific type, the vectors can be extracted in an obvious way."
      ],
      "metadata": {
        "id": "5IzvNgqdMpU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[0]"
      ],
      "metadata": {
        "id": "8qv8bMYReKMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendation"
      ],
      "metadata": {
        "id": "R7coHYXBPwyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example, we select the song *Who's That Chick*, from *Rihanna*."
      ],
      "metadata": {
        "id": "7zy4Het7ecbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(songs.iloc[12])"
      ],
      "metadata": {
        "id": "k6R6TmPSasc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The recommended songs will be those similar to the song with ID 12. We get them with the method `.most_similar()`. The parameter `positive` indicates that we search for similar vectors. With `negative`, we can work in the opposite way. The default number of similar vectors is 10, so we have restricted the search here.\n",
        "\n",
        "Note that the vectors created by Gensim Word2Vec are not normalized, but we don't have to care, because the default similarity of Word2Vec is the **cosine similarity**."
      ],
      "metadata": {
        "id": "LSvEuffqcfKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recs = model.wv.most_similar(positive='12', topn=5)\n",
        "recs"
      ],
      "metadata": {
        "id": "SuZrLjNPbdVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On top of the list, we get the song with ID 68, which is *Boom Boom Pow*, by *Black Eyed Peas*. Hope you agree with that."
      ],
      "metadata": {
        "id": "JA0F0u18dv20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(songs.iloc[np.array(recs)[:, 0]])"
      ],
      "metadata": {
        "id": "sZsqzAFWdeEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*. By replicating this example, you will find that Gensim Word2Vec does not create exactly the same vectors every time you train the model. According to Gensim documentation, this is due to \"ordering jitter from OS thread scheduling\". You can fix that with the argument `workers=1`."
      ],
      "metadata": {
        "id": "rruiixrimdUK"
      }
    }
  ]
}
