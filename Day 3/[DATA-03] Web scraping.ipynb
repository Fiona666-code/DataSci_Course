{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEAOyQiJorzJS6j7SokKgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MCanela-1954/DataSci_Course/blob/main/%5BDATA-03%5D%20Web%20scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [DATA-03] Web scraping"
      ],
      "metadata": {
        "id": "H4yzGhXXaEZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is HTML?"
      ],
      "metadata": {
        "id": "dRO3JWaWaNAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML** (Hypertext Markup Language) is the language in which are written the documents designed to be displayed in a web browser. The web browser receives an HTML document from a web server or from local storage and renders it as a multimedia web page. That HTML document is then called the **page source**.\n",
        "\n",
        "HTML is assisted by two technologies:\n",
        "\n",
        "* **CSS** (Cascading Style Sheets) is a language used to describe the **style** of HTML documents.\n",
        "\n",
        "* **JavaScript** is a **scripting language**, that is, one for integrating and communicating with other languages. Scripting languages are used for small jobs. The source of a dynamic web page typically contains JavaScript scripts to perform actions such as accepting cookies or asking for more information."
      ],
      "metadata": {
        "id": "xWY5kcVcaQs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example"
      ],
      "metadata": {
        "id": "jFx8YqP_BXkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An extremely simple example of an HTML document follows. It is easy to see, in this example, why HTML is called a **markup language**. The markup, consisting here of the **tags** `<head>`, `<body>`, `<title>`, `<div>` and `<a>`, is used to create a structure in the document and to include **links** to other files.\n",
        "\n",
        "```\n",
        "<html>\n",
        "<head>\n",
        "\t<title>Data Viz</title>\n",
        "</head>\n",
        "<body>\n",
        "\t<div class=\"course\">Data Visualization</div>\n",
        "\t<div class=\"program\">MBA full-time</div>\n",
        "\t<a class=\"professor\" href=\"faculty-research/faculty/miguel-angel-canela\">Miguel Ángel Canela</a>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "Unfortunately, in an HTML document captured from Internet, you will not find such a friendly presentation, with one line for each tag, and indentation to help you see the structure of the document. But you can find in Internet various tools for rendering HTML documents in this form."
      ],
      "metadata": {
        "id": "wgqROznjBdV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tags and attributes"
      ],
      "metadata": {
        "id": "7-mJF24kaU8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The structure of an HTML document is made by the tags. Every part of the document is opened by a **start tag** (`<tag>`) and closed by an **end tag** (`</tag>`). These parts are called **HTML elements**. The tags create a tree-like structure in the document, with HTML elements nested within HTML elements. The representation of the HTML document as a logical tree is called the **Document Object Model** (DOM).\n",
        "\n",
        "*Note*. Though we may insert white space between consecutive elements to make the document readable, as in the example below, the white space between tags that belong to different elements is ignored by the HTML interpreter.\n",
        "\n",
        "The tag `<html>` tells the browser that this is an HTML document. The `html` element is the whole document. It has two **child elements**, `head` and `body`. An HTML document is always split in this way. In the example, the `head` element has one **child**, while the `body` element has three children, which are **siblings**.\n",
        "\n",
        "Then, the `title` element contains the string `'Data Viz'`, enclosed between the start tag and the end tag (this can also be said of the `head` element). This string is referred to as **text**. Also, most of the start tags have **attributes**. In our example, the `div` elements have one `class` attribute, while the `a` element has two attributes, a `class` attribute and a `href` attribute. `class` attributes, which specify one or more `class` names for some elements of the HTML document, are very frequent. The value of a `class` attribute can be used by CSS to provide style and by JavaScript to perform certain tasks for the elements with that `class` value.\n",
        "\n",
        "The `a` tags have a special role, to mark hyperlinks. A **hyperlink** is used to link a page to another page, or to download a file. The most important attribute of an `a` element is the `href` attribute, which indicates the link's destination.\n",
        "\n",
        "There are other HTML tag names, not used in the above example. In this course, they will be explained as they appear in other examples."
      ],
      "metadata": {
        "id": "OXe_wilxaZfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Beautiful Soup?"
      ],
      "metadata": {
        "id": "VyJWYW8RafU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beautiful Soup** is a Python package for extracting data from HTML files. Other packages, like **scrapy**, provide more adavanced toolkits, but, since Beautiful Soup is much friendlier, most **web scraping** practitioners start there.\n",
        "\n",
        "Beautiful Soup is available in Colab notebooks, but you may have to install it if you are working in your computer.This can be done by running in the shell (or in a Jupyter app) the command `pip install bs4`. When the package is already installed, the recommended import style is:"
      ],
      "metadata": {
        "id": "pn2UX6QnaiDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "F34P1ACcak_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This allows us to use the function `BeautifulSoup()`, which can be applied to any string containing HTML code. `BeautifulSoup()` **parses** the HTML code, learning the tree structure encoded there, which is then stored in a **soup object**. Let us see how this works in our example.\n",
        "\n",
        "In web scraping projects, HTML documents are captured from Internet, as shown later in this note. For this brief tutorial, we create a string variable, whose value is the HTML document. The triple quote mark stops the Python interpreter having trouble with the line breaks."
      ],
      "metadata": {
        "id": "mkjg9UbnanT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_str = '''\n",
        "<html>\n",
        "  <head>\n",
        "    <title>Data Viz</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div class=\"course\">Data Visualization</div>\n",
        "    <div class=\"program\">MBA full-time</div>\n",
        "    <a class=\"professor\" href=\"faculty-research/faculty/miguel-angel-canela\">Miguel Ángel Canela</a>\n",
        "  </body>\n",
        "</html>\n",
        "'''"
      ],
      "metadata": {
        "id": "i7GsndiAarsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing HTML code"
      ],
      "metadata": {
        "id": "6MS-OMdHbUFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To parse the string `html_str`, learning the tree structure, we enter:"
      ],
      "metadata": {
        "id": "Wfu9Z9-xbcam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html_str, 'html.parser')"
      ],
      "metadata": {
        "id": "jmDSctETbe_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`BeautifulSoup()` returns a `BeautifulSoup`\n",
        " object, which is a data structure representing a parsed HTML document. This data structure stores the contents of the string `html_str` in a way that the different HTML elements can be extracted. To get this, it uses a **parser**, which is a program which splits the string in substrings, based on the tags.\n",
        "\n",
        "Beautiful Soup does not come with a parser. The default option chooses among those available to the current Python kernel, following internal rules. The actual choice depends on the packages already installed in your computer (or cloud computing provider). If `html.parser` is specified, the choice is the parser provided by the Python Standard Library. Since this is a rather technical issue, we follow here the recommended practice."
      ],
      "metadata": {
        "id": "b5FZ61Dubhmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(soup)"
      ],
      "metadata": {
        "id": "TJeYxo1Hbki3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The contents of `soup` can be displayed (don't do this for the source of a real web page, which will be too big to be read on the screen):"
      ],
      "metadata": {
        "id": "30FiHi6mbrkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup"
      ],
      "metadata": {
        "id": "CtPyuxqYbyOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same is true por the elements contained in `soup`, as we will see below. But we have to see first how to extract this elements from the soup.\n"
      ],
      "metadata": {
        "id": "I_SSUiRpb1sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The tree structure"
      ],
      "metadata": {
        "id": "wXPxa-oJcCl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have a soup, you can easily explore the the content. For instance:"
      ],
      "metadata": {
        "id": "qiIdQF-fcFJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.head"
      ],
      "metadata": {
        "id": "KctwvLZ9cHIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(soup.head)"
      ],
      "metadata": {
        "id": "04eEOst_cKDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Though, formally, `BeautifulSoup` and `Tag` are different types, a tag works in practice as a smaller soup, so you can extract elements within elements:"
      ],
      "metadata": {
        "id": "Qs2ptcVvcO4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.head.title"
      ],
      "metadata": {
        "id": "r4xbrq84cUjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OMZM6zIbM5ZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you ask for a nonexisting element, you get `None`:"
      ],
      "metadata": {
        "id": "AhBjH9w9cWdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.head.div"
      ],
      "metadata": {
        "id": "GS77po5ucZZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When there are several elements satisfying the requirements, you get the first one. This is the logic of Beautiful Soup:"
      ],
      "metadata": {
        "id": "MjLNRGkfccSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.div"
      ],
      "metadata": {
        "id": "sO8gqlJecfVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplest way to extract tags from the soup is based on the methods `.find()` and `.find_all()`:\n",
        "\n",
        "* `.find_all()` returns a list containing all the HTML elements that satisfy a specification (eventually empty).\n",
        "\n",
        "* `.find()` returns only the first one (or `None`, if there is no element satisfying the specification).\n",
        "\n",
        "Let us see how to use these methods in our example."
      ],
      "metadata": {
        "id": "PXN-GwN5chb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The method .find()"
      ],
      "metadata": {
        "id": "r2qd34Nfckgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A first example of `.find()` follows."
      ],
      "metadata": {
        "id": "_0_BHHd6cn5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('div')"
      ],
      "metadata": {
        "id": "3giPN5t6cp2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that there are two `div` elements in this soup, and `.find()` has extracted the first one. But we can use the attribute values to distinguish among elements with the same tag name:"
      ],
      "metadata": {
        "id": "-G-KA3vVcr-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('div', attrs={'class': 'program'})"
      ],
      "metadata": {
        "id": "xFqldIBpcyct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the attribute `class`, this is can be shortened, as:"
      ],
      "metadata": {
        "id": "lhk_coq2c0dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('div', 'program')"
      ],
      "metadata": {
        "id": "tPv4ZuVAc28d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since a tag works as a smaller soup, you can iterate the method `.find()`:"
      ],
      "metadata": {
        "id": "veyQdbY6c5BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('head').find('title')"
      ],
      "metadata": {
        "id": "X6eaLQVBc7MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The method .find_all()"
      ],
      "metadata": {
        "id": "jWy8y2ridB1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method `.find_all()` uses the same syntax as `.find()` but, instead of a single element, it returns a list with all the elements that satisfy the specification:"
      ],
      "metadata": {
        "id": "CqLrXwL6dEZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('div')"
      ],
      "metadata": {
        "id": "WoccFlXrdSIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that `.find_all()` *always* returns a list. The list can be empty (`.find()` would return `None` in that case)."
      ],
      "metadata": {
        "id": "K-6xi7XCdUQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('head').find_all('div')"
      ],
      "metadata": {
        "id": "LLsPluVXdZaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When there is only one element in the list, that element is precisely the one returned by `.find()`:\n"
      ],
      "metadata": {
        "id": "CyFfZV4odbSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('div', 'course')"
      ],
      "metadata": {
        "id": "n_u4nTkhddZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, even when there is exactly one element in the list returned by `.find_all()`, you have to extract it from the list:"
      ],
      "metadata": {
        "id": "bD7HwoHcdgVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('div', 'course')[0]"
      ],
      "metadata": {
        "id": "LIK6N_gAdiXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting information from an HTML element"
      ],
      "metadata": {
        "id": "I1NVYd44dkgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The information that we wish to extract from an HTML element can come as the text enclosed by the start tag and the end tag, or as the value of an attribute. With `.string`, we can extract the text enclosed by the tags:"
      ],
      "metadata": {
        "id": "Etp6SKwpdmxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('a').string"
      ],
      "metadata": {
        "id": "gZfU_M5Qdo5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this method cannot be applied directly to a list returned by `.find_all()`:\n"
      ],
      "metadata": {
        "id": "bkYG6p_IdtAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('div').string"
      ],
      "metadata": {
        "id": "sTLEalWQdvV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But we can use a **comprehension list** to extract the text from every item of the list and store it in a new list:"
      ],
      "metadata": {
        "id": "f0oRGdKMdxbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[t.string for t in soup.find_all('div')]"
      ],
      "metadata": {
        "id": "pbvkpIJLSiU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In certain cases, we are interested in the value of an attribute. A frequent example is that of an `a` element with a `href` attribute whose value is a relevant link. The link is then extracted as:\n"
      ],
      "metadata": {
        "id": "Kw3rxpHod0ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('a')['href']"
      ],
      "metadata": {
        "id": "qeiRjjRfd5Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is web scraping?"
      ],
      "metadata": {
        "id": "ixHKqFStd7VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Web scraping** is concerned with extracting data from websites, in particular data that would be difficult to get on a large scale using traditional data collection methods. There is a whole industry built around web scraping, as it is used to track product price changes or discounts, to gather data from social profiles, to capture real estate listings, in search engine optimization (SEO), etc.\n",
        "\n",
        "Scraping a web page involves downloading the page and extracting data from it. Both things can be done in many ways, in particular with Python tools. There are also commercial web scraping applications, such as **Apify** and **Octoparse**. This course uses the Python packages **Requests** and **Beautiful Soup**."
      ],
      "metadata": {
        "id": "7NsvTEbzq-3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HTML and the browser"
      ],
      "metadata": {
        "id": "TWvyDkXtrDY0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that your browser (let us assume that you use Google Chrome) is displaying a web page on the screen. Right-clicking anywhere on the page opens a contextual menu. Then, selecting the *View Page Source* option, a new tab will open, displaying a HTML document. In the simplest case, which is the one covered in this lecture, this HTML document corresponds to the page that the browser was displaying.\n",
        "\n",
        "But not all pages are that simple. Some use a technology called **AJAX** (Asynchronous JavaScript And XML) in a two-step process as follows:\n",
        "\n",
        "1. The page corresponding to the URL that you enter is loaded.\n",
        "\n",
        "2. A JavaScript program creates a `XMLHttpRequest` object.\n",
        "\n",
        "3. The `XMLHttpRequest` object sends a request to a web server.\n",
        "\n",
        "4. The server sends a new HTML document back to the browser, which the browser displays on the screen. This second document corresponds to the page that you are actually watching.\n",
        "\n",
        "The tools provided by the Python package **Requests** can only capture the first page, which is not always the one from which you wish to scrape the information. To get the second one, web scrapers use a tool called **Selenium**, not covered in this course.\n",
        "\n",
        "Also in the contextual menu of the browser, the option *Inspect*  can help you to find the HTML code chunk corresponding to a specific part of a web page. Right-clicking on the part of the page currently displayed by the browser on which you are interested, and selecting *Inspect*, the screen is split, leaving the web page on one side and displaying on the other side the panel *Developer Tools*, which provides many choices: *Elements*, *Console*, *Network*, etc. The first one contains the page's DOM tree and gives you full access to the source code of the page currently displayed, which may be different from the one you called, as explained above. The element of the page on which you have clicked appears highlighted."
      ],
      "metadata": {
        "id": "EYaDGAoqrHMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The package Requests"
      ],
      "metadata": {
        "id": "Pl1Fjby2rK5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, files can be downloaded from Internet sources in multiple ways. Though some sources still recommend the package `urllib`, which is part of the Python Standard Library. But, nowadays, Requests, available in Colab notebooks and the Anaconda distribution, is the favorite choice of the practitioners.\n",
        "\n",
        "Let us refresh the context. Through the browser, you can access to a resource by specifying a **Uniform Resource Locator** (URL). At the beginning of the URL, we find the the protocol used to access the resource, followed by a colon and two forward slashes. This is usually HTTPS, a secure version of HTTP.\n",
        "\n",
        "The **Hypertext Transfer Protocol** (HTTP) was designed to enable communications between clients and servers. For instance, a client (such as your browser) sends a **HTTP request** to the server. Then, the server returns the response to the client. The response contains status information about the request and, if the request is accepted, the requested content.\n",
        "\n",
        "**GET** is one of the most common HTTP methods. It is used to request data from a specified resource. The Requests function `get()` is a Python implementation. You can manage this as follows:\n",
        "\n",
        "```\n",
        "import requests\n",
        "html_str = requests.get(url).text\n",
        "```\n",
        "\n",
        "`get()` returns a `requests` object (type `requests.models.Response`), containing data about the request. The attribute `text` of this object is a string which, for an ordinary web page, is the HTML source code. Then, you can extract the information sought as explained in this note. That information, after some cleaning, can be exported to your preferred data format."
      ],
      "metadata": {
        "id": "v7tw92eqrOLc"
      }
    }
  ]
}
